{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9794e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6601163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc5d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434710e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Shallow MLP': nn.Sequential(\n",
    "        nn.Linear(128*128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 3)\n",
    "    ),\n",
    "    'Deep MLP': nn.Sequential(\n",
    "        nn.Linear(128*128, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 3)\n",
    "    ),\n",
    "    'Shallow CNN': nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(32*64*64, 3) \n",
    "    ),\n",
    "    'Deep CNN': nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64*32*32, 128),  \n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 3)\n",
    "    )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de902d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIdetec_CNN(Dataset):\n",
    "    def __init__(self, data_dir=\"data\", img_size=128):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_dir = os.path.join(data_dir, \"initial_data\")\n",
    "        self.df = pd.read_csv(os.path.join(data_dir, \"initial_data.csv\"))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = os.path.basename(row[\"file_name\"])  \n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"No se encontró la imagen: {img_path}\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42543392",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIdetec_MLP(Dataset):\n",
    "    def __init__(self, data_dir=\"data\", img_size=128):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_dir = os.path.join(data_dir, \"initial_data\")\n",
    "        self.df = pd.read_csv(os.path.join(data_dir, \"initial_data.csv\"))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Lambda(lambda x: x.view(-1))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = os.path.basename(row[\"file_name\"])  \n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"No se encontró la imagen: {img_path}\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3315e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_CNN = AIdetec_CNN('../data', 128)\n",
    "\n",
    "train_size_CNN = 800    \n",
    "val_size_CNN = 200\n",
    "\n",
    "train_CNN, val_CNN = random_split(dataset_CNN, [train_size_CNN, val_size_CNN])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_MLP = AIdetec_MLP('../data', 128)\n",
    "\n",
    "train_size_MLP = 800    \n",
    "val_size_MLP = 200\n",
    "\n",
    "train_MLP, val_MLP = random_split(dataset_MLP, [train_size_MLP, val_size_MLP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72bb845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_CNN = DataLoader(train_CNN, batch_size=32, shuffle=True)\n",
    "dl_val_CNN = DataLoader(val_CNN, batch_size=32, shuffle=True)\n",
    "\n",
    "dl_train_MLP = DataLoader(train_MLP, batch_size=32, shuffle=True)\n",
    "dl_val_MLP = DataLoader(val_MLP, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "965edd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 16384])\n",
      "torch.Size([32])\n",
      "Total size:  800\n"
     ]
    }
   ],
   "source": [
    "size = 0\n",
    "for batch_x, batch_y in dl_train_MLP:\n",
    "  size += batch_x.shape[0]\n",
    "  print(batch_x.shape), print(batch_y.shape)\n",
    "print(\"Total size: \", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64fd92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, val_dl, epochs=1000, lr=0.1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        for batch_x, batch_y in train_dl:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        train_loss_history.append(train_loss / len(train_dl))\n",
    "        train_acc_history.append(train_correct / len(train_dl.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_dl:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                output = model(batch_x)\n",
    "                loss = criterion(output, batch_y)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        val_loss_history.append(val_loss / len(val_dl))\n",
    "        val_acc_history.append(val_correct / len(val_dl.dataset))\n",
    "\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss_history[-1]:.4f}, Train Acc: {train_acc_history[-1]:.4f}, Val Loss: {val_loss_history[-1]:.4f}, Val Acc: {val_acc_history[-1]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    return train_loss_history, train_acc_history, val_loss_history, val_acc_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5cc305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 2.6420, Train Acc: 0.4775, Val Loss: 1.7237, Val Acc: 0.5200\n",
      "Epoch 1, Train Loss: 0.9926, Train Acc: 0.5288, Val Loss: 0.6890, Val Acc: 0.5400\n",
      "Epoch 2, Train Loss: 0.8053, Train Acc: 0.5737, Val Loss: 1.1207, Val Acc: 0.4850\n",
      "Epoch 3, Train Loss: 0.7239, Train Acc: 0.5850, Val Loss: 0.7040, Val Acc: 0.5400\n",
      "Epoch 4, Train Loss: 0.6776, Train Acc: 0.6038, Val Loss: 0.8943, Val Acc: 0.5200\n",
      "Epoch 5, Train Loss: 0.6479, Train Acc: 0.6288, Val Loss: 0.7774, Val Acc: 0.5050\n",
      "Epoch 6, Train Loss: 0.7484, Train Acc: 0.6038, Val Loss: 0.7529, Val Acc: 0.5300\n",
      "Epoch 7, Train Loss: 0.6631, Train Acc: 0.6200, Val Loss: 0.7683, Val Acc: 0.5600\n",
      "Epoch 8, Train Loss: 0.6862, Train Acc: 0.6325, Val Loss: 0.8540, Val Acc: 0.4950\n",
      "Epoch 9, Train Loss: 0.5830, Train Acc: 0.6937, Val Loss: 0.7293, Val Acc: 0.5800\n"
     ]
    }
   ],
   "source": [
    "train_loss_history, train_acc_history, val_loss_history, val_acc_history = train_model(models['Shallow MLP'], dl_train_MLP, dl_val_MLP, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af7a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.8936, Train Acc: 0.5100, Val Loss: 0.6947, Val Acc: 0.5350\n",
      "Epoch 1, Train Loss: 0.7228, Train Acc: 0.4800, Val Loss: 0.8479, Val Acc: 0.4800\n",
      "Epoch 2, Train Loss: 0.7602, Train Acc: 0.5150, Val Loss: 0.6961, Val Acc: 0.5150\n",
      "Epoch 3, Train Loss: 0.6985, Train Acc: 0.5162, Val Loss: 0.7311, Val Acc: 0.5200\n",
      "Epoch 4, Train Loss: 0.6854, Train Acc: 0.5437, Val Loss: 0.6900, Val Acc: 0.4650\n",
      "Epoch 5, Train Loss: 0.6797, Train Acc: 0.5475, Val Loss: 0.7049, Val Acc: 0.5300\n",
      "Epoch 6, Train Loss: 0.6672, Train Acc: 0.5950, Val Loss: 0.7115, Val Acc: 0.4900\n",
      "Epoch 7, Train Loss: 0.6994, Train Acc: 0.5387, Val Loss: 0.7342, Val Acc: 0.5300\n",
      "Epoch 8, Train Loss: 0.6667, Train Acc: 0.5850, Val Loss: 0.7058, Val Acc: 0.5000\n",
      "Epoch 9, Train Loss: 0.6782, Train Acc: 0.5687, Val Loss: 0.6813, Val Acc: 0.5100\n"
     ]
    }
   ],
   "source": [
    "train_loss_history, train_acc_history, val_loss_history, val_acc_history = train_model(models['Deep MLP'], dl_train_MLP, dl_val_MLP, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ade0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 3.7366, Train Acc: 0.5825, Val Loss: 0.5393, Val Acc: 0.7900\n",
      "Epoch 1, Train Loss: 0.5669, Train Acc: 0.7638, Val Loss: 0.6738, Val Acc: 0.7350\n",
      "Epoch 2, Train Loss: 0.2921, Train Acc: 0.8838, Val Loss: 0.3990, Val Acc: 0.8300\n",
      "Epoch 3, Train Loss: 0.2547, Train Acc: 0.8962, Val Loss: 0.3265, Val Acc: 0.8550\n",
      "Epoch 4, Train Loss: 0.1557, Train Acc: 0.9425, Val Loss: 0.3225, Val Acc: 0.8500\n",
      "Epoch 5, Train Loss: 0.1026, Train Acc: 0.9738, Val Loss: 0.3312, Val Acc: 0.8550\n",
      "Epoch 6, Train Loss: 0.1008, Train Acc: 0.9762, Val Loss: 0.3831, Val Acc: 0.8700\n",
      "Epoch 7, Train Loss: 0.0633, Train Acc: 0.9838, Val Loss: 0.3010, Val Acc: 0.8650\n",
      "Epoch 8, Train Loss: 0.0474, Train Acc: 0.9938, Val Loss: 0.4378, Val Acc: 0.8550\n",
      "Epoch 9, Train Loss: 0.0437, Train Acc: 0.9925, Val Loss: 0.3740, Val Acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "train_loss_history, train_acc_history, val_loss_history, val_acc_history = train_model(models['Shallow CNN'], dl_train_CNN, dl_val_CNN, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a75e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.8053, Train Acc: 0.5675, Val Loss: 0.7279, Val Acc: 0.6500\n",
      "Epoch 1, Train Loss: 0.4187, Train Acc: 0.8125, Val Loss: 0.4317, Val Acc: 0.8550\n",
      "Epoch 2, Train Loss: 0.2635, Train Acc: 0.8938, Val Loss: 0.3102, Val Acc: 0.8550\n",
      "Epoch 3, Train Loss: 0.2354, Train Acc: 0.9062, Val Loss: 0.2988, Val Acc: 0.8450\n",
      "Epoch 4, Train Loss: 0.2286, Train Acc: 0.9187, Val Loss: 0.5622, Val Acc: 0.8300\n",
      "Epoch 5, Train Loss: 0.1837, Train Acc: 0.9425, Val Loss: 0.4752, Val Acc: 0.8100\n",
      "Epoch 6, Train Loss: 0.1207, Train Acc: 0.9637, Val Loss: 0.3181, Val Acc: 0.8600\n",
      "Epoch 7, Train Loss: 0.0905, Train Acc: 0.9750, Val Loss: 0.3808, Val Acc: 0.8100\n",
      "Epoch 8, Train Loss: 0.1271, Train Acc: 0.9625, Val Loss: 0.3051, Val Acc: 0.8700\n",
      "Epoch 9, Train Loss: 0.0468, Train Acc: 0.9850, Val Loss: 0.3814, Val Acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "train_loss_history, train_acc_history, val_loss_history, val_acc_history = train_model(models['Deep CNN'], dl_train_CNN, dl_val_CNN, epochs=10, lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
